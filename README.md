# ğŸ“˜ Demand Forecasting Assistant  
### (LLM + Streamlit + Ollama + LightGBM + RAG)

Ce projet fournit une interface Streamlit permettant dâ€™interagir avec un **assistant intelligent spÃ©cialisÃ© en prÃ©visions de la demande**, basÃ© sur :

- Un modÃ¨le **LGBM** dÃ©jÃ  entraÃ®nÃ© pour prÃ©dire la demande **journaliÃ¨re**
- Les LabelEncoder associÃ©s
- Un csv contenant les prÃ©dictions pour les 31 jours aprÃ¨s les donnÃ©es initiales
- Un pipeline **RAG** utilisant SentenceTransformer + ChromaDB.
- Un grand modÃ¨le de langage **Qwen2.5:14B** exÃ©cutÃ© via **Ollama**.
- Une interface Web pour poser des questions et obtenir des rÃ©ponses analytiques.
- Une architecture **Docker Compose** comprenant un service Ollama et un service Streamlit.
  
Le notebook **Quantity Order Forecast.ipynb** correspond aux Ã©tapes suivis pour l'entraÃ®nement du modÃ¨le de prÃ©dictions.
---

## ğŸ§© PrÃ©requis

- Docker  
- Docker Compose  
- (Optionnel mais conseillÃ©) au moins 16 Go de RAM pour Qwen2.5:14B
---

## ğŸš€ Installation & Lancement

Lancer simplement depuis la racine du projet :

```bash
docker-compose up --build
```
Ce qui va :

DÃ©marrer Ollama

TÃ©lÃ©charger automatiquement qwen2.5:14b et servir le modÃ¨le

DÃ©marrer Streamlit

Servir lâ€™interface sur :

ğŸ‘‰ http://localhost:8501
